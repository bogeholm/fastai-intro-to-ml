{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course lecture\n",
    "[2 - Random Forest Deep Dive](http://course18.fast.ai/lessonsml1/lesson2.html)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bogeholm/fastai-intro-to-ml/blob/master/2-random-forest-deep-dive.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "## Lessons from last\n",
    "- Learn the metric (RMSE log sale price)\n",
    "- All columns should be _numbers_\n",
    "  - `datetime` -> `bool`eans (`dayofweek`, `dayofyear`, ...)\n",
    "  - All string values must be categorized\n",
    "- Missing values replaced by median\n",
    "- Additional boolean column `f'{colname}_na'` added to indicate missing values\n",
    "\n",
    "## This time\n",
    "- Discussion of [$R^2$](https://en.wikipedia.org/wiki/Coefficient_of_determination) in the context of [overfitting](https://en.wikipedia.org/wiki/Overfitting) and the [validation set](https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets)\n",
    "- Validation sets vs. training sets - **test set** is reserved for validating model after training and choosing hyperparameters on the **validation set** (*unclear which set is used for which - ask Google*)\n",
    "- If the test set represents a different time period than the training set, so should the validation set\n",
    "\n",
    "### Speeding things up\n",
    "- Choose a smaller subset of the data for interactive use\n",
    "- Build model with sinle tree (32:00)\n",
    "\n",
    "### Random Forests\n",
    "- A tree consists of a set of binary decisions\n",
    "- How do you split the trees?\n",
    "   - Eg. try every possible split of every possible value, and find the one with the best weighted average of MSE in the two groups\n",
    " - The tree is finished when there is only one element in each leaf node (default `scikit-learn` behavior)\n",
    "- A *Forest* is made of *Trees*. The Forest is made of Trees by Bagging. See \"Bag of Little Bootstraps\", a method of *ensembling*.\n",
    "- Method: Create a largish set of trees, that massively overfits on a random subset of the data. They all have random errors. What is the average of a set of random errors?\n",
    "- `scikit-learn` pick random subsets with replacement, ie. Bootstrapping.\n",
    "- The goal of Random Forests is to come up with 'predictive, but poorly correlated trees' (find link to original 1990's paper)\n",
    "- Un-correlated trees is more important than accurate trees - see `scikit-learn`'s `XtraTreesRegresor`\n",
    "- When turning off bootstrapping (`bootstrap=False`), the shallow tree will be contained in a deeper tree\n",
    "\n",
    "### Hyperparameters\n",
    "#### Number of trees\n",
    "- `scikit-learn` parameter `n_estimators`\n",
    "\n",
    "#### Out-of-bag score\n",
    "- At each level, use unused rows a validation sets (`oob_score=True` in `scikit-learn`) (1:12:00)\n",
    "\n",
    "#### Subsampling\n",
    "- If you pick a random subset for each tree, it doesn't matter how much data you have\n",
    "\n",
    "#### Growing trees less deeply\n",
    "- `scikit-learn` parameter `min_samples_leaf` - determines the minimum number of data points in the leaves. `3` suggested.\n",
    "\n",
    "#### Maximum number of features\n",
    "- `scikit-learn` parameter `max_features` The less correlated your trees are, the better. Takes a different subset of columns at each split point. Try `0.5`, `sqrt` or `log2`\n",
    "\n",
    "## Implementation plan\n",
    "- [x] Q: Can you fit on a DataFrame with categories added, but columns still in place? A: [Not this way at least](https://github.com/bogeholm/dataworks/blob/master/dev/jupyter/df-categories-and-codes.ipynb)\n",
    "- [ ] Split data to smaller, 'interactive' set\n",
    "- [ ] Draw a single tree\n",
    "- [ ] Run the `RandomForestRegressor`, see predictions of the single trees ('`estimators`') (51:16)\n",
    "- [ ] Define `print_score()` with `oob_score`\n",
    "- [ ] Predict with each tree in a Forest, and compare with the mean (1:05)\n",
    "- [ ] Plot metrics of one tree, then average of two trees, then ... (1:06:55)\n",
    "- [ ] Run with 20, 30, 40 trees (1:08:10)\n",
    "- [ ] Look at `set_rf_samples` and `reset_rf_samples` (from `fast.ai`, a \"horrible hack\") (1:16:00 and 1:19)\n",
    "...\n",
    "- [ ] Compare results with `XtraTreesRegressor`\n",
    "- [ ] Move `get_basepath()` to separate file \n",
    "\n",
    "# Tips\n",
    "## Notebook tips\n",
    "- `?` to view documentation of imported functions\n",
    "- `??` to view source code of imported functions\n",
    "\n",
    "## Python tips\n",
    "- `print(f'{variable}_string')`\n",
    "- Saving with [`to_feather`](https://github.com/wesm/feather/tree/master/python)\n",
    "\n",
    "## ML Tips\n",
    "- \"Most people run al of thei models, on all of their data, all of the time\" (around 1:20). This is pointless. Do most of the modelling on a reasonably large subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "## Install [dataworks](https://github.com/bogeholm/dataworks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to install utilities:\n",
    "!pip install --upgrade --quiet git+git://github.com/bogeholm/dataworks.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "from dataworks.df_utils import (add_datefields, \n",
    "                                add_nan_columns, \n",
    "                                categorize_df,\n",
    "                                inspect_df, \n",
    "                                numeric_nans, \n",
    "                                summarize_df, \n",
    "                                )\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mount Google Drive (for [Colab](https://colab.research.google.com/) integration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basepath(relative_dir_local='data', relative_dir_google='data'):\n",
    "    \"\"\" Return path to base directory depending on whether the\n",
    "        notebook is running locally, or in Google Colab. If the notebook\n",
    "        is running in Colab, data is loaded from Google Drive\n",
    "    \"\"\"\n",
    "    GOOGLE_DRIVE_HOME = 'drive/My Drive/' # Equivalent to `cd ~` in Google Drive\n",
    "    # https://stackoverflow.com/questions/39125532/file-does-not-exist-in-jupyter-notebook\n",
    "    #JUPYTER_CWD =  os.path.dirname(os.path.abspath(''))\n",
    "    JUPYTER_CWD =  os.path.abspath('')\n",
    "    \n",
    "    if 'google.colab' in sys.modules:\n",
    "        # Notebook is running in Google Colab\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        return os.path.join(GOOGLE_DRIVE_HOME, relative_dir_google)\n",
    "    else:\n",
    "        return os.path.join(JUPYTER_CWD, relative_dir_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tbm\\Documents\\machinelearning\\fastai-intro-to-ml\n",
      "DATAPATH: C:\\Users\\tbm\\Documents\\machinelearning\\fastai-intro-to-ml\\data\\bulldozers\n"
     ]
    }
   ],
   "source": [
    "DATAPATH = os.path.join(get_basepath(), 'bulldozers')\n",
    "print(f'DATAPATH: {DATAPATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_allrows(df):\n",
    "    \"\"\" Override max rows and display them all\n",
    "    \"\"\"\n",
    "    with pd.option_context('display.max_rows', len(df)):\n",
    "            display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start learning ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(DATAPATH, 'Train.zip')\n",
    "df_raw = pd.read_csv(filename, low_memory=False, parse_dates=['saledate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalesID</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>MachineID</th>\n",
       "      <th>ModelID</th>\n",
       "      <th>datasource</th>\n",
       "      <th>...</th>\n",
       "      <th>Backhoe_Mounting</th>\n",
       "      <th>Blade_Type</th>\n",
       "      <th>Travel_Controls</th>\n",
       "      <th>Differential_Type</th>\n",
       "      <th>Steering_Controls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1139246</td>\n",
       "      <td>66000</td>\n",
       "      <td>999089</td>\n",
       "      <td>3157</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Conventional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1139248</td>\n",
       "      <td>57000</td>\n",
       "      <td>117657</td>\n",
       "      <td>77</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Conventional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139249</td>\n",
       "      <td>10000</td>\n",
       "      <td>434808</td>\n",
       "      <td>7009</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1139251</td>\n",
       "      <td>38500</td>\n",
       "      <td>1026470</td>\n",
       "      <td>332</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1139253</td>\n",
       "      <td>11000</td>\n",
       "      <td>1057373</td>\n",
       "      <td>17311</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalesID  SalePrice  MachineID  ModelID  datasource  ...  Backhoe_Mounting  \\\n",
       "0  1139246      66000     999089     3157         121  ...               NaN   \n",
       "1  1139248      57000     117657       77         121  ...               NaN   \n",
       "2  1139249      10000     434808     7009         121  ...               NaN   \n",
       "3  1139251      38500    1026470      332         121  ...               NaN   \n",
       "4  1139253      11000    1057373    17311         121  ...               NaN   \n",
       "\n",
       "   Blade_Type  Travel_Controls Differential_Type Steering_Controls  \n",
       "0         NaN              NaN          Standard      Conventional  \n",
       "1         NaN              NaN          Standard      Conventional  \n",
       "2         NaN              NaN               NaN               NaN  \n",
       "3         NaN              NaN               NaN               NaN  \n",
       "4         NaN              NaN               NaN               NaN  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "Essentially a summary of steps in [1-intro-to-random-forests](1-intro-to-random-forests.ipynb), but excluding the 'NaN indicator' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Log sale price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc = df_raw.copy(deep=True)\n",
    "if 'SalePrice' in df_proc.columns:\n",
    "    df_proc['LogSalePrice'] = np.log(df_proc['SalePrice'])\n",
    "    df_proc.drop(columns=['SalePrice'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Saledate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'saledate' in df_proc.columns:\n",
    "    df_proc = add_datefields(df_proc, 'saledate', drop_original=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Numerical nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc['auctioneerID'] = df_proc['auctioneerID'].fillna(\n",
    "    df_proc['auctioneerID'].max() + 1\n",
    ")\n",
    "\n",
    "df_proc['MachineHoursCurrentMeter'] = df_proc['MachineHoursCurrentMeter'].fillna(\n",
    "    df_proc['MachineHoursCurrentMeter'].median()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Categorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_cats, catcodes) = categorize_df(df_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>ncols</th>\n",
       "      <th>ncols_w_nans</th>\n",
       "      <th>n_nans</th>\n",
       "      <th>n_total</th>\n",
       "      <th>nan_frac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bool</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1604500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>float64</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1203375</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>int16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1604500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>int64</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3610125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>int8</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16045000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type  ncols  ncols_w_nans  n_nans   n_total  nan_frac\n",
       "0     bool      4             0       0   1604500       0.0\n",
       "1  float64      3             0       0   1203375       0.0\n",
       "2    int16      4             0       0   1604500       0.0\n",
       "3    int64      9             0       0   3610125       0.0\n",
       "4     int8     40             0       0  16045000       0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_df(df_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
